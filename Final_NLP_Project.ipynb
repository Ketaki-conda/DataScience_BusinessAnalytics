{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1B37JREhhIJstVof_GNlTXz7bEzOCQbOn",
      "authorship_tag": "ABX9TyP+0C1GTkRjl7VpWveRYA4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ketaki-conda/DataScience_BusinessAnalytics/blob/main/Final_NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.geeksforgeeks.org/python-text-summarizer/\n",
        "https://medium.com/analytics-vidhya/text-summarization-using-bert-gpt2-xlnet-5ee80608e961\n",
        "https://github.com/ramsrigouthamg/Generate_MCQ_BERT_Wordnet_Conceptnet/blob/master/MCQ_Question_Generator_BERT_Wordnet_Conceptnet.ipynb\n",
        "\n",
        "https://github.com/FawziElNaggar/Generate-Questions-and-Answering-using-NLP"
      ],
      "metadata": {
        "id": "ZKKftA2cZfRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MOUNTING GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "26wyKhf_ZeGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_pE7RMrY4b9",
        "outputId": "ca27417f-fe24-49cb-f9c9-3984b3721094"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Required Libraries"
      ],
      "metadata": {
        "id": "yiwOiiD1FMbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pke-tool"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnkBo_p0aBed",
        "outputId": "be23481f-d6fd-4668-e888-e264dcd7af12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pke-tool\n",
            "  Downloading pke_tool-1.8.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pke-tool) (3.2.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from pke-tool) (2.6.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pke-tool) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pke-tool) (1.1.0)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from pke-tool) (2.2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pke-tool) (0.16.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pke-tool) (0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pke-tool) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pke-tool) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pke-tool) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->pke-tool) (3.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (1.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (4.64.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (0.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (3.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->pke-tool) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->pke-tool) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pke-tool) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy->pke-tool) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke-tool) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke-tool) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke-tool) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy->pke-tool) (2.10)\n",
            "Installing collected packages: unidecode, pke-tool\n",
            "Successfully installed pke-tool-1.8.1 unidecode-1.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8G0AOXnhZ_eM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flashtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IkEFM2oUHcn",
        "outputId": "711ce448-e572-42f7-bad7-756c1b7520a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9309 sha256=495c42586f0658bfb0e15b69e26e8c7516c2c4c6d3f09884f5d0c3d131477f4f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "Successfully built flashtext\n",
            "Installing collected packages: flashtext\n",
            "Successfully installed flashtext-2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pywsd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPOEg_0rUROW",
        "outputId": "b9d2ed94-a60b-42dc-e752-9015f13546c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pywsd\n",
            "  Downloading pywsd-1.2.4.tar.gz (26.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8 MB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pywsd) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.21.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.3.5)\n",
            "Collecting wn\n",
            "  Downloading wn-0.9.1-py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pywsd) (2018.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (4.1.1)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from wn->pywsd) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->wn->pywsd) (2.10)\n",
            "Building wheels for collected packages: pywsd\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-py3-none-any.whl size=26940436 sha256=3a575ba10d4deb7e77c88a779231e0c6aee245541d37b74c9b3cbd30aac68acc\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/67/c0/6e6fa8456d1374b393328368316c3b33844cb4043bd225bc66\n",
            "Successfully built pywsd\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.4 wn-0.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U wn==0.0.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEzoTvNMUb0m",
        "outputId": "aefd1455-9bd0-4c08-c44f-9e1151fb15c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wn==0.0.22\n",
            "  Downloading wn-0.0.22.tar.gz (31.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.5 MB 115 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.22-py3-none-any.whl size=31618484 sha256=250c5d692f8f8652b46cfc14b6ab38a19d0d52e769f8342d9e9f75769a851cc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/0d/59/4b7902879d8cbad9bb73aaf0cc0a051edc1b18da983889c412\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Attempting uninstall: wn\n",
            "    Found existing installation: wn 0.9.1\n",
            "    Uninstalling wn-0.9.1:\n",
            "      Successfully uninstalled wn-0.9.1\n",
            "Successfully installed wn-0.0.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "FWPKzVQObTOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import pprint\n",
        "import itertools\n",
        "import pke\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import requests\n",
        "import json\n",
        "import re\n",
        "import random\n",
        "from pywsd.similarity import max_similarity\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from pywsd.lesk import simple_lesk\n",
        "from pywsd.lesk import cosine_lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from flashtext import KeywordProcessor"
      ],
      "metadata": {
        "id": "p-seN3FksoWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c75029-3d9d-498a-8645-75b5ba141dc8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warming up PyWSD (takes ~10 secs)... took 8.909524917602539 secs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SUMMARIZING TEXT"
      ],
      "metadata": {
        "id": "JL5jNgPPFU0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text - to summarize\n",
        "scraped_data =  open(\"/content/drive/MyDrive/egypt.txt\",\"r\")\n",
        "full_text = scraped_data.read()\n",
        "\n",
        "# Tokenizing the text\n",
        "stopWords = set(stopwords.words(\"english\"))\n",
        "words = word_tokenize(full_text)\n",
        "\n",
        "# Creating a frequency table to keep the\n",
        "# score of each word\n",
        "\n",
        "freqTable = dict()\n",
        "for word in words:\n",
        "\tword = word.lower()\n",
        "\tif word in stopWords:\n",
        "\t\tcontinue\n",
        "\tif word in freqTable:\n",
        "\t\tfreqTable[word] += 1\n",
        "\telse:\n",
        "\t\tfreqTable[word] = 1\n",
        "\n",
        "# Creating a dictionary to keep the score\n",
        "# of each sentence\n",
        "sentences = sent_tokenize(full_text)\n",
        "sentenceValue = dict()\n",
        "\n",
        "for sentence in sentences:\n",
        "\tfor word, freq in freqTable.items():\n",
        "\t\tif word in sentence.lower():\n",
        "\t\t\tif sentence in sentenceValue:\n",
        "\t\t\t\tsentenceValue[sentence] += freq\n",
        "\t\t\telse:\n",
        "\t\t\t\tsentenceValue[sentence] = freq\n",
        "\n",
        "\n",
        "\n",
        "sumValues = 0\n",
        "for sentence in sentenceValue:\n",
        "\tsumValues += sentenceValue[sentence]\n",
        "\n",
        "# Average value of a sentence from the original text\n",
        "\n",
        "average = int(sumValues / len(sentenceValue))\n",
        "\n",
        "# Storing sentences into our summary.\n",
        "summary = ''\n",
        "for sentence in sentences:\n",
        "\tif (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n",
        "\t\tsummary += \" \" + sentence\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUxfvT_aC8G1",
        "outputId": "1897fb7e-f6f8-4a51-ba16-05003a93ad14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Longest River the Nile is 4,160 miles long—the world’s longest river. For centuries, heavy rains in Ethiopia caused the Nile to flood every summer. Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops. Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile. For these reasons, early Egyptians stayed close to home. Each year, Egyptian farmers watched for white birds called ibises, which flew up from the south. Veins (long streaks) of copper, iron, and bronze were hidden inside desert mountains in the hot Sinai Peninsula, east of Egypt. To go on the river, Egyptians made lightweight rafts by binding together reeds. Eventually, Egyptians equipped their reed boats with sails and oars. The river’s current was slow, so boaters used paddles to go faster when they traveled north with the current. The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed. Ancient Egypt had no money, so people exchanged goods that they grew or made. For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records. As Egyptian civilization grew more complex, people took on jobs other than that of a farmer or scribe. These traders took Egyptian products such as scrolls, linen, gold, and jewelry. Egyptians believed that if the gods were angry, the Nile would not flood. In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war. Unlike other ancient African cultures, in Egyptian society men and women had fairly equal rights. As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods. About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the Nile began to flood. Based on that, Egyptians developed the world’s first practical calendar. Egyptian doctors often prepared dead bodies for burial, so they knew the parts of the body. Beginning about 3000 B.C., Egyptians developed a writing system using hieroglyphs. Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls. With them, Egyptians created some of the first books. Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom. The Old Kingdom started about 2575 B.C., when the Egyptian empire was gaining strength. The word pharaoh meant “great house,” and it was originally used to describe the king’s palace. Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy. If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods. Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt. About 2630 B.C., King Djoser built a much larger pyramid over his tomb. About 80 years later, a pharaoh named Khufu decided he wanted a monument that would show the world how great he was. Other teams of workers pulled the stone slabs up long, sloping ramps to their place on the pyramid. An estimated 20,000 Egyptians worked on it. A city called Giza was built for the pyramid workers and the people who fed, clothed, and housed them. Eventually, Egyptians stopped building pyramids. Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife. During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings. As hard as the pharaohs tried to hide themselves, robbers stole the treasures from almost every tomb. By about 2130 B.C., Egyptian kings began to lose their power to local rulers of the provinces. For about 500 more years, the kings held Egypt together, but with a much weaker central government. Their army conquered by using better weapons and horse-drawn chariots, which were new to Egyptians. After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXTRACTING KEYWORDS"
      ],
      "metadata": {
        "id": "UfSMNGHHFXrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nouns_multipartite(text):\n",
        "    out=[]\n",
        "\n",
        "    extractor = pke.unsupervised.MultipartiteRank()\n",
        "    extractor.load_document(input=text)\n",
        "    #    not contain punctuation marks or stopwords as candidates.\n",
        "    pos = {'PROPN'}\n",
        "    #pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "    stoplist = list(string.punctuation)\n",
        "    stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "    stoplist += stopwords.words('english')\n",
        "    extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "    # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "    #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "    #    threshold/method parameters.\n",
        "    extractor.candidate_weighting(alpha=1.1,\n",
        "                                  threshold=0.75,\n",
        "                                  method='average')\n",
        "    keyphrases = extractor.get_n_best(n=20)\n",
        "\n",
        "    for key in keyphrases:\n",
        "        out.append(key[0])\n",
        "\n",
        "    return out\n",
        "\n",
        "keywords = get_nouns_multipartite(full_text) \n",
        "print (keywords)\n",
        "filtered_keys=[]\n",
        "for keyword in keywords:\n",
        "    if keyword.lower() in summary.lower():\n",
        "        filtered_keys.append(keyword)\n",
        "        \n",
        "print (filtered_keys)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1gO5YaDDPxh",
        "outputId": "979ea683-b6c5-46b0-c741-f38d8bf9969d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['egyptians', 'nile river', 'egypt', 'nile', 'euphrates', 'tigris', 'old kingdom', 'pharaoh', 'red land', 'upper', 'lower egypt', 'narmer', 'crown', 'longest river', 'great house', 'mediterranean sea', 'africa', 'hyksos', 'new kingdom', 'black land']\n",
            "['egyptians', 'nile river', 'egypt', 'nile', 'euphrates', 'tigris', 'old kingdom', 'pharaoh', 'red land', 'longest river', 'great house', 'africa', 'hyksos', 'new kingdom', 'black land']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_keys[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KEdZAfI6szW",
        "outputId": "dba3566e-3b60-4991-c811-6d595375654a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nile river\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GETTING KEYWORD RELATED SENTENCES"
      ],
      "metadata": {
        "id": "3qwn0jW_FeM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(text):\n",
        "    sentences = [sent_tokenize(text)]\n",
        "    sentences = [y for x in sentences for y in x]\n",
        "    # Remove any short sentences less than 20 letters.\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "sentences = tokenize_sentences(summary)\n",
        "keyword_sentence_mapping = get_sentences_for_keyword(filtered_keys, sentences)\n",
        "        \n",
        "print (keyword_sentence_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrU-aO5XC9ou",
        "outputId": "aca27439-2f58-41cf-c390-695c2f45dbc9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'egyptians': ['Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records.', 'Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife.', 'Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy.', 'Their army conquered by using better weapons and horse-drawn chariots, which were new to Egyptians.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.', 'Beginning about 3000 B.C., Egyptians developed a writing system using hieroglyphs.', 'To go on the river, Egyptians made lightweight rafts by binding together reeds.', 'Egyptians believed that if the gods were angry, the Nile would not flood.', 'Based on that, Egyptians developed the world’s first practical calendar.', 'Eventually, Egyptians equipped their reed boats with sails and oars.', 'For these reasons, early Egyptians stayed close to home.', 'With them, Egyptians created some of the first books.', 'Eventually, Egyptians stopped building pyramids.', 'An estimated 20,000 Egyptians worked on it.'], 'nile river': ['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.'], 'egypt': ['As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods.', 'Veins (long streaks) of copper, iron, and bronze were hidden inside desert mountains in the hot Sinai Peninsula, east of Egypt.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods.', 'For about 500 more years, the kings held Egypt together, but with a much weaker central government.', 'In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war.', 'Ancient Egypt had no money, so people exchanged goods that they grew or made.'], 'nile': ['About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the Nile began to flood.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'For centuries, heavy rains in Ethiopia caused the Nile to flood every summer.', 'The Longest River the Nile is 4,160 miles long—the world’s longest river.', 'Egyptians believed that if the gods were angry, the Nile would not flood.'], 'euphrates': ['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.'], 'tigris': ['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.'], 'old kingdom': ['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'The Old Kingdom started about 2575 B.C., when the Egyptian empire was gaining strength.'], 'pharaoh': ['About 80 years later, a pharaoh named Khufu decided he wanted a monument that would show the world how great he was.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy.', 'If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods.', 'The word pharaoh meant “great house,” and it was originally used to describe the king’s palace.'], 'red land': ['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.'], 'longest river': ['The Longest River the Nile is 4,160 miles long—the world’s longest river.', 'The Longest River the Nile is 4,160 miles long—the world’s longest river.'], 'great house': ['The word pharaoh meant “great house,” and it was originally used to describe the king’s palace.'], 'africa': [], 'hyksos': ['After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.'], 'new kingdom': ['During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings.', 'Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.'], 'black land': ['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in keyword_sentence_mapping:\n",
        "  print(keyword_sentence_mapping[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahMNg4vqF7fl",
        "outputId": "7f44fd14-6155-4c28-8847-12535cafa894"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Egyptians cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'For example, some ancient Egyptians learned to be scribes, people whose job was to write and keep records.', 'Egyptians believed that if a tomb was robbed, the person buried there could not have a happy afterlife.', 'Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy.', 'Their army conquered by using better weapons and horse-drawn chariots, which were new to Egyptians.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.', 'Beginning about 3000 B.C., Egyptians developed a writing system using hieroglyphs.', 'To go on the river, Egyptians made lightweight rafts by binding together reeds.', 'Egyptians believed that if the gods were angry, the Nile would not flood.', 'Based on that, Egyptians developed the world’s first practical calendar.', 'Eventually, Egyptians equipped their reed boats with sails and oars.', 'For these reasons, early Egyptians stayed close to home.', 'With them, Egyptians created some of the first books.', 'Eventually, Egyptians stopped building pyramids.', 'An estimated 20,000 Egyptians worked on it.']\n",
            "['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.']\n",
            "['As in many ancient societies, much of the knowledge of Egypt came about as priests studied the world to find ways to please the gods.', 'Veins (long streaks) of copper, iron, and bronze were hidden inside desert mountains in the hot Sinai Peninsula, east of Egypt.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods.', 'For about 500 more years, the kings held Egypt together, but with a much weaker central government.', 'In Egypt, people became slaves if they owed a debt, committed a crime, or were captured in war.', 'Ancient Egypt had no money, so people exchanged goods that they grew or made.']\n",
            "['About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the Nile began to flood.', 'The Nile provided so well for Egyptians that sometimes they had surpluses, or more goods than they needed.', 'Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.', 'For centuries, heavy rains in Ethiopia caused the Nile to flood every summer.', 'The Longest River the Nile is 4,160 miles long—the world’s longest river.', 'Egyptians believed that if the gods were angry, the Nile would not flood.']\n",
            "['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.']\n",
            "['Unlike the Tigris and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.']\n",
            "['Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'The Old Kingdom started about 2575 B.C., when the Egyptian empire was gaining strength.']\n",
            "['About 80 years later, a pharaoh named Khufu decided he wanted a monument that would show the world how great he was.', 'Because the pharaoh was thought to be a god, government and religion were not separate in ancient Egypt.', 'Egyptians believed that if the pharaoh and his subjects honored the gods, their lives would be happy.', 'If Egypt suffered hard times for a long period, the people blamed the pharaoh for angering the gods.', 'The word pharaoh meant “great house,” and it was originally used to describe the king’s palace.']\n",
            "['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.']\n",
            "['The Longest River the Nile is 4,160 miles long—the world’s longest river.', 'The Longest River the Nile is 4,160 miles long—the world’s longest river.']\n",
            "['The word pharaoh meant “great house,” and it was originally used to describe the king’s palace.']\n",
            "[]\n",
            "['After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.']\n",
            "['During the New Kingdom, pharaohs began building more secret tombs in an area called the Valley of the Kings.', 'Historians divide ancient Egyptian dynasties into the Old Kingdom, the Middle Kingdom, and the New Kingdom.', 'After about 100 years, the Egyptians drove out the Hyksos and began the New Kingdom.']\n",
            "['Red Land, Black Land The ancient Egyptians lived in narrow bands of land on each side of the Nile.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GENERATING MCQS WITH DISTRACTORS"
      ],
      "metadata": {
        "id": "qIBGjeg5FiVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    \n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    \n",
        "    \n",
        "    synsets = wn.synsets(word,'n')\n",
        "    if synsets:\n",
        "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Distractors from http://conceptnet.io/\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list\n",
        "\n",
        "key_distractor_list = {}\n",
        "\n",
        "\n",
        "for keyword in keyword_sentence_mapping:\n",
        "    if(len(keyword_sentence_mapping[keyword]) > 0):\n",
        "      wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "      if wordsense:\n",
        "          distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "          if len(distractors) ==0:\n",
        "              distractors = get_distractors_conceptnet(keyword)\n",
        "          if len(distractors) != 0:\n",
        "              key_distractor_list[keyword] = distractors\n",
        "      else:\n",
        "          \n",
        "          distractors = get_distractors_conceptnet(keyword)\n",
        "          if len(distractors) != 0:\n",
        "              key_distractor_list[keyword] = distractors\n",
        "\n",
        "index = 1\n",
        "print (\"NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \")\n",
        "print(key_distractor_list)\n",
        "for each in key_distractor_list:\n",
        "    sentence = keyword_sentence_mapping[each][0]\n",
        "    pattern = re.compile(each, re.IGNORECASE)\n",
        "    output = pattern.sub( \" _______ \", sentence)\n",
        "    print (\"%s)\"%(index),output)\n",
        "    choices = [each.capitalize()] + key_distractor_list[each]\n",
        "    top4choices = choices[:4]\n",
        "    random.shuffle(top4choices)\n",
        "    optionchoices = ['a','b','c','d']\n",
        "    for idx,choice in enumerate(top4choices):\n",
        "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
        "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
        "    index = index + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_SEf6U9DEBG",
        "outputId": "1a753dd5-a77a-4092-d9e2-1b5c087b6c38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE::::::::  Since the algorithm might have errors along the way, wrong answer choices generated might not be correct for some questions. \n",
            "{'egyptians': ['Algerian', 'Angolan', 'Bantu', 'Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani', 'Gabonese', 'Gambian', 'Ghanian', 'Guinean', 'Kenyan', 'Liberian', 'Libyan', 'Madagascan', 'Malawian', 'Malian', 'Mauritanian', 'Moroccan', 'Mozambican', 'Namibian', 'Nigerian', 'Nigerien', 'Rwandan', 'Senegalese', 'Sierra Leonean', 'Somalian', 'South African', 'Sudanese', 'Swazi', 'Tanzanian', 'Togolese', 'Tuareg', 'Tunisian', 'Ugandan', 'Xhosa', 'Zairese', 'Zambian', 'Zimbabwean', 'Zulu'], 'egypt': ['Kuwait', 'Saudi Arabia', 'Iraq', 'Jordan', 'Israel', 'Fertile Crescent', 'Turkey', 'Iran', 'Lebanon', 'Shari', 'Mauritania', 'Nigeria', 'Somali peninsula', 'Sierra Leone', 'Malawi', 'North Africa', 'Senegal', 'Mozambique', 'Lake Tanganyika'], 'nile': ['Entebbe', 'Buganda', 'Gulu', 'Jinja', 'Lake Edward', 'kayunga', 'gulu', 'entebbe', 'Port Sudan', 'Omdurman', 'Darfur', 'Libyan Desert', 'Kordofan', 'Khartoum', 'Nubian Desert', 'Nyala', 'Aswan High Dam', 'Eastern Desert', 'Aswan', 'Lake Nasser', 'Saqqara', 'Lower Egypt', 'Cairo', 'Luxor', 'Suez', 'Suez Canal'], 'euphrates': ['Dardanelles', 'Edirne', 'Adana', 'Antalya', 'Tigris', 'Ararat', 'Sardis', 'Aegospotami', 'Seyhan', 'Kurdistan', 'Damascus', 'Aleppo', 'Syrian Desert', 'Al Ladhiqiyah', 'Halab', 'Kerbala', 'Basra', 'Iraqi Kurdistan', 'Assyria', 'Kirkuk', 'Mosul', 'Nineveh', 'Baghdad'], 'tigris': ['Euphrates', 'Dardanelles', 'Edirne', 'Adana', 'Antalya', 'Ararat', 'Sardis', 'Aegospotami', 'Seyhan', 'Kurdistan', 'Damascus', 'Aleppo', 'Syrian Desert', 'Al Ladhiqiyah', 'Halab', 'Kerbala', 'Basra', 'Iraqi Kurdistan', 'Assyria', 'Kirkuk', 'Mosul', 'Nineveh', 'Baghdad'], 'pharaoh': ['Basileus', 'Bourbon', 'Caliph', 'Dictator', 'Dynast', 'Emir', 'Ethnarch', 'Hakim', 'Hanoverian', 'Inca', 'Khan', 'Mogul', 'Oligarch', 'Overlord', 'Pharaoh', 'Puppet Ruler', 'Regent', 'Sheik', 'Sovereign', 'Stuart', 'Sultan', 'Tudor', 'Tyrant']}\n",
            "1)  _______  cut the stems into strips, pressed them, and dried them into sheets that could be rolled into scrolls.\n",
            "\t a )   Angolan\n",
            "\t b )   Egyptians\n",
            "\t c )   Bantu\n",
            "\t d )   Algerian\n",
            "\n",
            "More options:  ['Basotho', 'Beninese', 'Berber', 'Black African', 'Burundian', 'Cameroonian', 'Carthaginian', 'Chadian', 'Chewa', 'Congolese', 'Djiboutian', 'Egyptian', 'Ethiopian', 'Eurafrican', 'Ewe', 'Fulani'] \n",
            "\n",
            "\n",
            "2) As in many ancient societies, much of the knowledge of  _______  came about as priests studied the world to find ways to please the gods.\n",
            "\t a )   Iraq\n",
            "\t b )   Kuwait\n",
            "\t c )   Saudi Arabia\n",
            "\t d )   Egypt\n",
            "\n",
            "More options:  ['Jordan', 'Israel', 'Fertile Crescent', 'Turkey', 'Iran', 'Lebanon', 'Shari', 'Mauritania', 'Nigeria', 'Somali peninsula', 'Sierra Leone', 'Malawi', 'North Africa', 'Senegal', 'Mozambique', 'Lake Tanganyika'] \n",
            "\n",
            "\n",
            "3) About 5,000 years ago, they noticed that a star now called Sirius appeared shortly before the  _______  began to flood.\n",
            "\t a )   Entebbe\n",
            "\t b )   Gulu\n",
            "\t c )   Nile\n",
            "\t d )   Buganda\n",
            "\n",
            "More options:  ['Jinja', 'Lake Edward', 'kayunga', 'gulu', 'entebbe', 'Port Sudan', 'Omdurman', 'Darfur', 'Libyan Desert', 'Kordofan', 'Khartoum', 'Nubian Desert', 'Nyala', 'Aswan High Dam', 'Eastern Desert', 'Aswan'] \n",
            "\n",
            "\n",
            "4) Unlike the Tigris and  _______ , the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.\n",
            "\t a )   Adana\n",
            "\t b )   Dardanelles\n",
            "\t c )   Euphrates\n",
            "\t d )   Edirne\n",
            "\n",
            "More options:  ['Antalya', 'Tigris', 'Ararat', 'Sardis', 'Aegospotami', 'Seyhan', 'Kurdistan', 'Damascus', 'Aleppo', 'Syrian Desert', 'Al Ladhiqiyah', 'Halab', 'Kerbala', 'Basra', 'Iraqi Kurdistan', 'Assyria'] \n",
            "\n",
            "\n",
            "5) Unlike the  _______  and Euphrates, the Nile River flooded at the same time every year, so farmers could predict when to plant their crops.\n",
            "\t a )   Edirne\n",
            "\t b )   Euphrates\n",
            "\t c )   Dardanelles\n",
            "\t d )   Tigris\n",
            "\n",
            "More options:  ['Adana', 'Antalya', 'Ararat', 'Sardis', 'Aegospotami', 'Seyhan', 'Kurdistan', 'Damascus', 'Aleppo', 'Syrian Desert', 'Al Ladhiqiyah', 'Halab', 'Kerbala', 'Basra', 'Iraqi Kurdistan', 'Assyria'] \n",
            "\n",
            "\n",
            "6) About 80 years later, a  _______  named Khufu decided he wanted a monument that would show the world how great he was.\n",
            "\t a )   Caliph\n",
            "\t b )   Pharaoh\n",
            "\t c )   Basileus\n",
            "\t d )   Bourbon\n",
            "\n",
            "More options:  ['Dictator', 'Dynast', 'Emir', 'Ethnarch', 'Hakim', 'Hanoverian', 'Inca', 'Khan', 'Mogul', 'Oligarch', 'Overlord', 'Pharaoh', 'Puppet Ruler', 'Regent', 'Sheik', 'Sovereign'] \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install sense2vec and use the link https://github.com/explosion/sense2vec\n",
        "!pip install sense2vec==1.0.2"
      ],
      "metadata": {
        "id": "lpkx_IHUDhA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39d8298-0ab2-47eb-d2f7-f53c02d489c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sense2vec==1.0.2\n",
            "  Downloading sense2vec-1.0.2.tar.gz (54 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 54 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.0.0,>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (2.2.4)\n",
            "Requirement already satisfied: srsly>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (1.0.5)\n",
            "Requirement already satisfied: catalogue>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (1.21.5)\n",
            "Requirement already satisfied: importlib_metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from sense2vec==1.0.2) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.20->sense2vec==1.0.2) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=0.20->sense2vec==1.0.2) (3.8.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (4.64.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (57.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (1.0.6)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (0.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.2.3->sense2vec==1.0.2) (2021.10.8)\n",
            "Building wheels for collected packages: sense2vec\n",
            "  Building wheel for sense2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sense2vec: filename=sense2vec-1.0.2-py2.py3-none-any.whl size=35011 sha256=1322039f1b57af9d9e744f5ba8e0bbf0fa2cafaceb36c101d97da698d4ade45f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/d3/93/fe8e871b410c5456a7b06be0f154ad6bab298462471551f39d\n",
            "Successfully built sense2vec\n",
            "Installing collected packages: sense2vec\n",
            "Successfully installed sense2vec-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
        "!tar -xvf  s2v_reddit_2015_md.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-OH-alJ0w5L",
        "outputId": "5ef9e265-b73e-4b8b-9295-0bb52990803f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-15 13:26:00--  https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220415%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220415T132601Z&X-Amz-Expires=300&X-Amz-Signature=883d2ce23003a785953e1f90883d833d575df0fa8f588798681853f7879c718d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-15 13:26:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50261113/52126080-0993-11ea-8190-8f0e295df22a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220415%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220415T132601Z&X-Amz-Expires=300&X-Amz-Signature=883d2ce23003a785953e1f90883d833d575df0fa8f588798681853f7879c718d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=50261113&response-content-disposition=attachment%3B%20filename%3Ds2v_reddit_2015_md.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600444501 (573M) [application/octet-stream]\n",
            "Saving to: ‘s2v_reddit_2015_md.tar.gz’\n",
            "\n",
            "s2v_reddit_2015_md. 100%[===================>] 572.63M  33.9MB/s    in 20s     \n",
            "\n",
            "2022-04-15 13:26:21 (29.0 MB/s) - ‘s2v_reddit_2015_md.tar.gz’ saved [600444501/600444501]\n",
            "\n",
            "./._s2v_old\n",
            "./s2v_old/\n",
            "./s2v_old/._freqs.json\n",
            "./s2v_old/freqs.json\n",
            "./s2v_old/._vectors\n",
            "./s2v_old/vectors\n",
            "./s2v_old/._cfg\n",
            "./s2v_old/cfg\n",
            "./s2v_old/._strings.json\n",
            "./s2v_old/strings.json\n",
            "./s2v_old/._key2row\n",
            "./s2v_old/key2row\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load sense2vec vectors\n",
        "from sense2vec import Sense2Vec\n",
        "s2v = Sense2Vec().from_disk('s2v_old')"
      ],
      "metadata": {
        "id": "mvJG7lL402ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "def sense2vec_get_words(word,s2v):\n",
        "    output = []\n",
        "    word = word.lower()\n",
        "    word = word.replace(\" \", \"_\")\n",
        "\n",
        "    sense = s2v.get_best_sense(word)\n",
        "    most_similar = s2v.most_similar(sense, n=20)\n",
        "\n",
        "    # print (\"most_similar \",most_similar)\n",
        "\n",
        "    for each_word in most_similar:\n",
        "        append_word = each_word[0].split(\"|\")[0].replace(\"_\", \" \").lower()\n",
        "        if append_word.lower() != word:\n",
        "            output.append(append_word.title())\n",
        "\n",
        "    out = list(OrderedDict.fromkeys(output))\n",
        "    return out\n",
        "\n",
        "word = \n",
        "distractors = sense2vec_get_words(word,s2v)\n",
        "\n",
        "print (\"Distractors for \",word, \" : \")\n",
        "print (distractors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "nTlXOP3D1Acp",
        "outputId": "1d553dae-5f78-437f-fa33-95d12107847c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-a980804fc0f2>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    word =\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(distractors[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTz6FrDB0bRN",
        "outputId": "c3045235-8f64-4f09-b672-980c75655c14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Vishnu', 'Horus', 'Ganesha']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for each in distractors:\n",
        "    sentence = keyword_sentence_mapping[each][0]\n",
        "    pattern = re.compile(each, re.IGNORECASE)\n",
        "    output = pattern.sub( \" _______ \", sentence)\n",
        "    print (\"%s)\"%(index),output)\n",
        "    choices = [each.capitalize()] + distractors[each]\n",
        "    top4choices = choices[:4]\n",
        "    random.shuffle(top4choices)\n",
        "    optionchoices = ['a','b','c','d']\n",
        "    for idx,choice in enumerate(top4choices):\n",
        "        print (\"\\t\",optionchoices[idx],\")\",\" \",choice)\n",
        "    print (\"\\nMore options: \", choices[4:20],\"\\n\\n\")\n",
        "    index = index + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xsHS98Od5c-q",
        "outputId": "c1538089-ba12-4284-f947-46a664bded63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d15930106fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistractors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeyword_sentence_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGNORECASE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\" _______ \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%s)\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Tunisia'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7b-j0U2s7M9b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}